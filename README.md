# ğŸ¯ Sentiment Analysis API using FastAPI & Machine Learning

This project performs **sentiment analysis** on text (movie reviews) and exposes a REST API using **FastAPI**.  
It predicts whether a given text is **Positive** or **Negative**, along with a **confidence score**.

---
## ğŸ§¾ Project Overview

| Feature                     | Details                                                                 |
|----------------------------|--------------------------------------------------------------------------|
| Project Name               | Sentiment Analysis API                                                    |
| Problem Type               | Binary Text Classification                                               |
| Dataset                    | IMDB Movie Reviews (50,000 labeled reviews)                              |
| Algorithm                  | TF-IDF + Logistic Regression                                             |
| Model Save Format          | Pickle (`.pkl`)                                                           |
| Deployment Framework       | FastAPI + Uvicorn                                                        |
| Input                      | Text (movie reviews)                                                     |
| Output                     | Sentiment (Positive / Negative) + Confidence Score                       |
| Accuracy Achieved          | ~90% Test Accuracy                                                        |


## ğŸ“Œ Features

- âœ”ï¸ Train ML model on IMDB Movie Reviews dataset  
- âœ”ï¸ Text vectorization using **TFâ€“IDF**
- âœ”ï¸ Classification model using **Logistic Regression**
- âœ”ï¸ Model saved as **pickle (.pkl)** file
- âœ”ï¸ FastAPI endpoint for real-time predictions
- âœ”ï¸ Swagger UI for API testing (`/docs`)
- âœ”ï¸ Handles confidence score using `predict_proba()`

---

## ğŸ§  Tech Stack

| Layer | Technology |
|------|-----------|
| Language | Python |
| ML Libraries | scikit-learn, pandas, pickle |
| Model | TF-IDF + Logistic Regression |
| Serving | FastAPI |
| Server | Uvicorn |
| Evaluation | Accuracy, Precision, Recall, F1 Score |

---

## ğŸ“ Project Structure

Movie Review Recommendation/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ IMDB Dataset.csv
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ sentiment_model.pkl
â”‚
â”œâ”€â”€ model_training.py # Training script (TF-IDF + Logistic Regression)
â”œâ”€â”€ main.py # FastAPI app (inference service)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

### 1ï¸âƒ£ Activate virtual environment
```bash
venv\Scripts\activate
2ï¸âƒ£ Install requirements
bash
Copy code
pip install -r requirements.txt
3ï¸âƒ£ Train the model
bash
Copy code
python model_training.py --data "data/IMDB Dataset.csv"
4ï¸âƒ£ Output example
yaml
Copy code
Train Accuracy : 0.9304
Test Accuracy  : 0.8999
F1 Score       : 0.9008
The trained model is saved in:

bash
Copy code
models/sentiment_model.pkl
ğŸ§ª Running API (FastAPI)
1ï¸âƒ£ Start server
bash
Copy code
uvicorn main:app --reload
2ï¸âƒ£ Open in browser
Swagger UI â†’ http://127.0.0.1:8000/docs

FastAPI root â†’ http://127.0.0.1:8000

ğŸ“® API Usage
Endpoint
bash
Copy code
POST /predict
Request (JSON)
json
Copy code
{
  "text": "This movie was absolutely amazing!"
}
Response (JSON)
json
Copy code
{
  "sentiment": "positive",
  "confidence": 0.9743
}
ğŸ“Š Evaluation Metrics
Accuracy

Precision

Recall

F1 Score

Train vs Test evaluation (to check overfitting)

Example:

yaml
Copy code
Train Accuracy : 93.04%
Test Accuracy  : 89.99%
Since the gap is small (~3%), the model is not overfitting.

ğŸ” How It Works
1ï¸âƒ£ Preprocessing
Convert text to lowercase

Stopwords removal

TF-IDF feature extraction

2ï¸âƒ£ Model
Logistic Regression with:

max_iter=1000

ngram_range=(1,2)

max_features=20000

3ï¸âƒ£ Inference
Load .pkl model

Predict class

Return class + confidence

ğŸ“š Concepts Used
Logistic Regression

TF-IDF vectorization

Binary Classification

Train-Test Split

Cross-Validation (optional)

FastAPI & Pydantic schema

ğŸ‘¨â€ğŸ’» Sample Code Snippet (FastAPI)
python
Copy code
from fastapi import FastAPI
import pickle

app = FastAPI()
model = pickle.load(open("models/sentiment_model.pkl", "rb"))

@app.post("/predict")
def predict(text: str):
    prediction = model.predict([text])[0]
    return {"sentiment": prediction}
ğŸ“ Future Improvements
Neutral sentiment class (Softmax model)

Streamlit / React frontend

Use pretrained embeddings (BERT, RoBERTa)

Deploy on AWS / Render / Railway

Database logging of predictions

Use spaCy / NLTK for better preprocessing

ğŸ¤ Contributing
PRs are welcome!
Feel free to open issues or suggest new features.

ğŸ§‘â€ğŸ’¼ Author
Your Rashmika Makwana

GitHub: rashmikad1743

Email: rashmikad1743@email.com

